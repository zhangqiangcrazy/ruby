/* -*- mode:c; style:ruby; coding: utf-8; indent-tabs-mode: nil -*- */

/* insns.def - YARV instruction definitions
 *
 * Copyright (C) 2004-2007 Koichi Sasada */

/* This file is a part of  the programming language Ruby.  Permission is hereby
 * granted, to either  redistribute and/or modify this file,  provided that the
 * conditions mentioned  in the  file COPYING  are met.   Consult the  file for
 * details. */

/* massive reformat by @shyouhei, to support per-insn attributes. */

/* structure
 * ---------
 *
 *  insn
 *  insn_name(ope)(pop)(ret)
 *      type decl, decl, ...;
 *  {
 *      attr type attr_name = { stmt; ... };
 *      attr type another_attr = { ... };
 *
 *      impl {
 *          arbitrary C code goes here...
 *      }
 *  }
 *
 * where
 *
 * insn_name: Name of the instruction e.g. "nop"
 * ope: Operands. Resides inside of ISeq.
 * pop: Values to pop from stack, "..." denotes variadic instruction.
 * ret: Values to push to stack, "..." also possible.
 * type decl: C variable declarations of ope/pop/ret.
 * attr_name: Name of an attribute e.g. "sp_inc"
 *
 * some notes
 * ----------
 *
 * - The "insn", "attr", and "impl" are keywords.
 *
 * - This syntax  is aimed  to be properly  colored by a  modern C  source code
 *   editor of your choice but not guaranteed.
 *
 * - Following  things  are  verbatimly  copied into  the  generated  C  source
 *   code. You must not define any evil macros that doesn't match curly braces.
 *
 *   - Those K&R-ish variable declarations
 *   - The { ... } part of every attributes.
 *   - The { ... } part right after keyword impl.
 *
 * - Attributes can see the operands.  But not stack variables.
 *
 * - Attributes  are generated  as  each  separate possibly-inlined  functions.
 *   Thus it makes no sense to have an attribute that does not return.
 *
 * - On the other hand  the instruction body is not a function.   It is a wrong
 *   idea to return from an instruction.  Doing so must result in a [BUG].
 *
 * attributes
 * ----------
 *
 * Any attributes can be attached  to any instructions but currently, following
 * attributes are recognized:
 *
 * sp_inc: By  defining this attribute  you can override stack  pointer growth.
 *         This  attribute  is  not  mandatory.   If  absent  stack  growth  is
 *         calculated from the instruction's push/pop count.
 *
 * purity: Tells if the instruction has  no side effect than given ope/pop/ret.
 *         Used for optimizations.  This is false if absent.
 *
 */

/* nop */
insn
nop()()()
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { /* none */ }
}

/**********************************************************/
/* deal with variables                                    */
/**********************************************************/

/* Get local variable (pointed by `idx' and `level').
 *   'level' indicates the nesting depth from the current block. */
insn
getlocal(idx, level)()(val)
    lindex_t idx;
    rb_num_t level;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val = *(vm_get_ep(GET_EP(), level) - idx); }
}

/* Set a local variable (pointed to by 'idx') as val.
 *   'level' indicates the nesting depth from the current block. */
insn
setlocal(idx, level)(val)()
    lindex_t idx;
    rb_num_t level;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { vm_env_write(vm_get_ep(GET_EP(), level), -(int)idx, val); }
}

/* Get value of special local variable ($~, $_, ..). */
insn
getspecial(key, type)()(val)
    rb_num_t key, type;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val = vm_getspecial(th, GET_LEP(), key, type); }
}

/* Set value of special local variable ($~, $_, ...) to obj. */
insn
setspecial(key)(obj)()
    rb_num_t key;
    VALUE obj;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { lep_svar_set(th, GET_LEP(), key, obj); }
}

/* Get value of instance variable id of self.
 *   If is_local is not 0, get value of class local variable. */
insn
getinstancevariable(id, ic)()(val)
    ID id;
    IC ic;
    VALUE val;
{
    impl { val = vm_getinstancevariable(GET_SELF(), id, ic); }
}

/* Set value of instance variable id of self to val.
 *   If is_local is not 0, set value of class local variable. */
insn
setinstancevariable(id, ic)(val)()
    ID id;
    IC ic;
    VALUE val;
{
    impl { vm_setinstancevariable(GET_SELF(), id, val, ic); }
}

/* Get value of class variable id of klass as val. */
insn
getclassvariable(id)()(val)
    ID id;
    VALUE val;
{
    impl {
        val = rb_cvar_get(vm_get_cvar_base(rb_vm_get_cref(GET_EP()), GET_CFP()), id);
    }
}

/* Set value of class variable id of klass as val. */
insn
setclassvariable(id)(val)()
    ID id;
    VALUE val;
{
    impl {
        vm_ensure_not_refinement_module(GET_SELF());
        rb_cvar_set(vm_get_cvar_base(rb_vm_get_cref(GET_EP()), GET_CFP()), id, val);
    }
}

/*
 * Get constant variable id. If klass is Qnil, constants
 * are searched in the current scope. If klass is Qfalse, constants
 * are searched as top level constants. Otherwise, get constant under klass
 * class or module. */
insn
getconstant(id)(klass)(val)
    ID id;
    VALUE klass, val;
{
    impl { val = vm_get_ev_const(th, klass, id, 0); }
}

/*
 * Set constant variable id. If klass is Qfalse, constant
 * is able to access in this scope. if klass is Qnil, set
 * top level constant. otherwise, set constant under klass
 * class or module.
 */
insn
setconstant(id)(val, cbase)()
    ID id;
    VALUE val, cbase;
{
    impl {
        vm_check_if_namespace(cbase);
        vm_ensure_not_refinement_module(GET_SELF());
        rb_const_set(cbase, id, val);
    }
}

/* get global variable id. */
insn
getglobal(entry)()(val)
    GENTRY entry;
    VALUE val;
{
    impl { val = GET_GLOBAL((VALUE)entry); }
}

/* set global variable id as val. */
insn
setglobal(entry)(val)()
    GENTRY entry;
    VALUE val;
{
    impl { SET_GLOBAL((VALUE)entry, val); }
}

/**********************************************************/
/* deal with values                                       */
/**********************************************************/

/* put nil to stack. */
insn
putnil()()(val)
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val = Qnil; }
}

/* put self. */
insn
putself()()(val)
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val = GET_SELF(); }
}

/* put some object.
 *   i.e. Fixnum, true, false, nil, and so on. */
insn
putobject(val)()(val)
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { /* */ }
}

/* put special object.  "value_type" is for expansion. */
insn
putspecialobject(value_type)()(val)
    rb_num_t value_type;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        enum vm_special_object_type type;
        type = (enum vm_special_object_type)value_type;
        val = vm_get_special_object(GET_EP(), type);
    }
}

/* put iseq value. */
insn
putiseq(iseq)()(ret)
    ISEQ iseq;
    VALUE ret;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { ret = (VALUE)iseq; }
}

/* put string val. string will be copied. */
insn
putstring(str)()(val)
    VALUE str, val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val = rb_str_resurrect(str); }
}

/* put concatenate strings */
insn
concatstrings(num)(...)(val)
    rb_num_t num;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return 1 - num; };

    impl { val = rb_str_concat_literals(num, STACK_ADDR_FROM_TOP(num)); }
}

/* push the result of to_str. */
insn
tostring()(val)(val)
    VALUE val;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* calls method */
    };

    impl { val = rb_obj_as_string(val); }
}

/* Freeze (dynamically) created strings. if debug_info is given, set it. */
insn
freezestring(debug_info)(str)(str)
    VALUE debug_info, str;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        if (!NIL_P(debug_info)) {
            rb_ivar_set(str, id_debug_created_info, debug_info);
        }
        rb_str_freeze(str);
    }
}

/* compile str to Regexp and push it.
 *   opt is the option for the Regexp. */
insn
toregexp(opt, cnt)(...)(val)
    rb_num_t opt, cnt;
    VALUE val;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* calls method */
    };
    attr rb_num_t sp_inc = { return 1 - cnt; };

    impl {
        VALUE rb_reg_new_ary(VALUE ary, int options);
        const VALUE ary = \
            rb_ary_tmp_new_from_values(0, cnt, STACK_ADDR_FROM_TOP(cnt));
        val = rb_reg_new_ary(ary, (int)opt);
        rb_ary_clear(ary);
    }
}

/* put new array initialized with num values on the stack. */
insn
newarray(num)(...)(val)
    rb_num_t num;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return 1 - num; };

    impl { val = rb_ary_new4(num, STACK_ADDR_FROM_TOP(num)); }
}

/* dup array */
insn
duparray(ary)()(val)
    VALUE ary, val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val = rb_ary_resurrect(ary); }
}

/* if TOS is an array expand, expand it to num objects.
 *   if the number of the array is less than num, push nils to fill.
 *   if it is greater than num, exceeding elements are dropped.
 *   unless TOS is an array, push num - 1 nils.
 *   if flags is non-zero, push the array of the rest elements.
 *   flag: 0x01 - rest args array
 *   flag: 0x02 - for postarg
 *   flag: 0x04 - reverse? */
insn
expandarray(num, flag)(..., ary)(...)
    rb_num_t num, flag;
    VALUE ary;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* calls method */
    };
    attr rb_num_t sp_inc = { return num - 1 + (flag & 1 ? 1 : 0); };

    impl { vm_expandarray(GET_CFP(), ary, num, (int)flag); }
}

/* concat two arrays */
insn
concatarray()(ary1, ary2)(ary)
    VALUE ary1, ary2, ary;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* calls method */
    };

    impl { ary = vm_concat_array(ary1, ary2); }
}

/* call to_a on array ary to splat */
insn
splatarray(flag)(ary)(obj)
    VALUE flag, ary, obj;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* calls method */
    };

    impl { obj = vm_splat_array(flag, ary); }
}

/* put new Hash from n elements. n must be an even number. */
insn
newhash(num)(...)(val)
    rb_num_t num;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return 1 - num; };

    impl {
        rb_num_t i;

        RUBY_DTRACE_CREATE_HOOK(HASH, num);

        val = rb_hash_new();

        for (i = num; i > 0; i -= 2) {
            const VALUE v = TOPN(i - 2);
            const VALUE k = TOPN(i - 1);
            rb_hash_aset(val, k, v);
        }
    }
}

/* put new Range object.(Range.new(low, high, flag)) */
insn
newrange(flag)(low, high)(val)
    rb_num_t flag;
    VALUE low, high, val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val = rb_range_new(low, high, (int)flag); }
}

/**********************************************************/
/* deal with stack operation                              */
/**********************************************************/

/* pop from stack. */
insn
pop()(val)()
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        (void)val;
        /* none */
    }
}

/* duplicate stack top. */
insn
dup()(val)(val1, val2)
    VALUE val, val1, val2;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { val1 = val2 = val; }
}

/* duplicate stack top n elements */
insn
dupn(n)(...)(...)
    rb_num_t n;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return n; };

    /* :FIXME: This code overruns the stack pointer before extending
     * it. We need alloca()-like mechanism to fix this. */
    impl { MEMCPY(GET_SP(), STACK_ADDR_FROM_TOP(n), VALUE, n); }
    /* For record: It has been like this since the beginning of
     * YARV. The overrun is (was) by design of @ko1. */
    /* https://svn.ruby-lang.org/cgi-bin/viewvc.cgi/trunk/insns.def?revision=11439&view=markup */
}

/* swap top 2 vals */
insn
swap()(val, obj)(obj, val)
    VALUE val, obj;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { /* none */ }
}

/* reverse stack top N order. */
insn
reverse(n)(...)(...)
    rb_num_t n;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return 0; };

    impl {
        rb_num_t i;
        VALUE *sp = STACK_ADDR_FROM_TOP(n);

        for (i=0; i<n/2; i++) {
            VALUE v0 = sp[i];
            VALUE v1 = TOPN(i);
            sp[i] = v1;
            TOPN(i) = v0;
        }
    }
}

/* for stack caching. */
insn
reput()(..., val)(val)
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return 0; };

    impl { /* none */ }
}

/* get nth stack value from stack top */
insn
topn(n)(...)(val)
    rb_num_t n;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return 1; };

    impl { val = TOPN(n); }
}

/* set Nth stack entry to stack top */
insn
setn(n)(..., val)(val)
    rb_num_t n;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return 0; };

    impl { TOPN(n) = val; }
}

/* empty current stack */
insn
adjuststack(n)(...)(...)
    rb_num_t n;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return - n; };

    impl { /* none */ }
}

/**********************************************************/
/* deal with setting                                      */
/**********************************************************/

/* defined? */
insn
defined(op_type, obj, needstr)(v)(val)
    rb_num_t op_type;
    VALUE obj, needstr, v, val;
{
    attr enum insn_purity purity = {
        switch (op_type) {
          case DEFINED_IVAR:
          case DEFINED_IVAR2:
          case DEFINED_GVAR:
          case DEFINED_CVAR:
          case DEFINED_YIELD:
          case DEFINED_REF:
            return insn_is_pure;
          case DEFINED_CONST:
            return insn_is_unpredictable; /* can kick autoload */
          case DEFINED_FUNC:
          case DEFINED_METHOD:
            return insn_is_unpredictable; /* can kick respond_to_missing? */
          case DEFINED_ZSUPER:
            return insn_is_unpredictable; /* what if super is method missing? */
          default:
            rb_bug("unknown operand %ld: blame @shyouhei.", op_type);
        }
    };

    impl { val = vm_defined(th, GET_CFP(), op_type, obj, needstr, v); }
}

/* check `target' matches `pattern'.
 *   `flag & VM_CHECKMATCH_TYPE_MASK' describe how to check pattern.
 *    VM_CHECKMATCH_TYPE_WHEN: ignore target and check pattern is truthy.
 *    VM_CHECKMATCH_TYPE_CASE: check `patten === target'.
 *    VM_CHECKMATCH_TYPE_RESCUE: check `pattern.kind_op?(Module) && pattern ==
 *       target'.
 *   if `flag & VM_CHECKMATCH_ARRAY' is not 0, then `patten' is array of
 *   patterns. */
insn
checkmatch(flag)(target, pattern)(result)
    rb_num_t flag;
    VALUE target, pattern, result;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* calls method */
    };

    impl { result = vm_check_match(target, pattern, flag); }
}

/* check keywords are specified or not. */
insn
checkkeyword(kw_bits_index, keyword_index)()(ret)
    lindex_t kw_bits_index;
    rb_num_t keyword_index;
    VALUE ret;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { ret = vm_check_keyword(kw_bits_index, keyword_index, GET_EP()); }
}

/* trace */
insn
trace(nf)()()
    rb_num_t nf;
{
    attr enum insn_purity purity = {
        extern rb_thread_t *ruby_current_thread;

        if (ruby_current_thread->vm->trace_running) {
            return insn_is_not_pure;
        }
        else {
            return insn_is_pure;
        }
    };

    impl {
        rb_event_flag_t flag = (rb_event_flag_t)nf;

        if (RUBY_DTRACE_METHOD_ENTRY_ENABLED() ||
            RUBY_DTRACE_METHOD_RETURN_ENABLED() ||
            RUBY_DTRACE_CMETHOD_ENTRY_ENABLED() ||
            RUBY_DTRACE_CMETHOD_RETURN_ENABLED()) {

            switch (flag) {
              case RUBY_EVENT_CALL:
                RUBY_DTRACE_METHOD_ENTRY_HOOK(th, 0, 0);
                break;
              case RUBY_EVENT_C_CALL:
                RUBY_DTRACE_CMETHOD_ENTRY_HOOK(th, 0, 0);
                break;
              case RUBY_EVENT_RETURN:
                RUBY_DTRACE_METHOD_RETURN_HOOK(th, 0, 0);
                break;
              case RUBY_EVENT_C_RETURN:
                RUBY_DTRACE_CMETHOD_RETURN_HOOK(th, 0, 0);
                break;
            }
        }

        EXEC_EVENT_HOOK(th, flag, GET_SELF(), 0, 0, 0 /* id and klass are resolved at callee */,
                        (flag & (RUBY_EVENT_RETURN | RUBY_EVENT_B_RETURN)) ? TOPN(0) : Qundef);
    }
}

/**********************************************************/
/* deal with control flow 1: class/module                 */
/**********************************************************/

/*
 * enter class definition scope. if super is Qfalse, and class
 * "klass" is defined, it's redefine. otherwise, define "klass" class. */
insn
defineclass(id, class_iseq, flags)(cbase, super)(val)
    ID id;
    ISEQ class_iseq;
    rb_num_t flags;
    VALUE cbase, super, val;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* global side effect */
    };

    impl {
        /* val is dummy */
        VALUE klass = vm_find_or_create_class(id, class_iseq, flags,
                                              cbase, super);

        rb_iseq_check(class_iseq);

        /* enter scope */
        POPN(2); /* wipe out cbase, super */
        vm_push_frame(th, class_iseq, VM_FRAME_MAGIC_CLASS | VM_ENV_FLAG_LOCAL, klass,
                      GET_BLOCK_HANDLER(),
                      (VALUE)vm_cref_push(th, klass, NULL, FALSE),
                      class_iseq->body->iseq_encoded, GET_SP(),
                      class_iseq->body->local_table_size,
                      class_iseq->body->stack_max);
        RESTORE_REGS();
        NEXT_INSN();
    }
}

/**********************************************************/
/* deal with control flow 2: method/iterator              */
/**********************************************************/

/* invoke method. */
insn
send(ci, cc, blockiseq)(...)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    ISEQ blockiseq;
    VALUE val;
{
    attr enum insn_purity purity = {
        enum insn_purity p1 = purity_of_cc(cc);
        enum insn_purity p2 = purity_of_iseq(blockiseq);

        /* This is where "depends_block" dependency is resolved */
        if (p1 == insn_depends_block) {
            return p2;
        }
        else {
            return purity_merge(p1, p2);
        }
    };
    attr rb_num_t sp_inc = {
        int yield_p = (ci->flag & VM_CALL_ARGS_BLOCKARG) ? 1 : 0;
        return - ci->orig_argc - yield_p;
    };

    impl {
        struct rb_calling_info calling;
        bool b;

        vm_caller_setup_arg_block(th, reg_cfp, &calling, ci, blockiseq, FALSE);
        b = vm_search_method(ci, cc, calling.recv = TOPN(calling.argc = ci->orig_argc));
        if (b) vm_propagate_purity(GET_ISEQ(), cc);
        CALL_METHOD(&calling, ci, cc);
    }
}

insn
opt_str_freeze(str)()(val)
    VALUE str, val;
{
    attr enum insn_purity purity = {
        /* You can't say if it is pure when String#freeze is
         * redefined.  Fall back to false for that case. */
        return purity_of_BOP(BOP_FREEZE, STRING_REDEFINED_OP_FLAG);
    };

    impl {
        if (BASIC_OP_UNREDEFINED_P(BOP_FREEZE, STRING_REDEFINED_OP_FLAG)) {
            val = str;
        }
        else {
            val = rb_funcall(rb_str_resurrect(str), idFreeze, 0);
        }
    }
}

insn
opt_newarray_max(num)(...)(val)
    rb_num_t num;
    VALUE val;
{
    attr enum insn_purity purity = {
        /* This instruction typically has no side effects.  But it
         * compares array contents each other by nature.  That part
         * can have side effects when redefined.  No way to detect
         * such redefinition beforehand.  We cannot but marke it being
         * not pure. */
        return insn_is_not_pure;
    };
    attr rb_num_t sp_inc = { return 1 - num; };

    impl { val = vm_opt_newarray_max(num, STACK_ADDR_FROM_TOP(num)); }
}

insn
opt_newarray_min(num)(...)(val)
    rb_num_t num;
    VALUE val;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* same discussion as opt_newarray_max */
    };
    attr rb_num_t sp_inc = { return 1 - num; };

    impl { val = vm_opt_newarray_min(num, STACK_ADDR_FROM_TOP(num)); }
}

/* Invoke method without block */
insn
opt_send_without_block(ci, cc)(...)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE val;
{
    attr enum insn_purity purity = { return purity_of_cc(cc); };
    attr rb_num_t sp_inc = { return -ci->orig_argc; };

    impl {
        struct rb_calling_info calling;
        bool b;

        calling.block_handler = VM_BLOCK_HANDLER_NONE;
        b = vm_search_method(ci, cc, calling.recv = TOPN(calling.argc = ci->orig_argc));
        if (b) vm_propagate_purity(GET_ISEQ(), cc);
        CALL_METHOD(&calling, ci, cc);
    }
}

/* super(args) # args.size => num */
insn
invokesuper(ci, cc, blockiseq)(...)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    ISEQ blockiseq;
    VALUE val;
{
    attr enum insn_purity purity = {
        enum insn_purity p1 = purity_of_cc(cc);
        enum insn_purity p2 = purity_of_iseq(blockiseq);

        /* This is where "depends_block" dependency is resolved */
        if (p1 == insn_depends_block) {
            return p2;
        }
        else {
            return purity_merge(p1, p2);
        }
    };
    attr rb_num_t sp_inc = {
        int yield_p = (ci->flag & VM_CALL_ARGS_BLOCKARG) ? 1 : 0;
        return - ci->orig_argc - yield_p;
    };

    impl {
        struct rb_calling_info calling;
        bool b;
        calling.argc = ci->orig_argc;

        vm_caller_setup_arg_block(th, reg_cfp, &calling, ci, blockiseq, TRUE);
        calling.recv = GET_SELF();
        b = vm_search_super_method(th, GET_CFP(), &calling, ci, cc);
        if (b) vm_propagate_purity(GET_ISEQ(), cc);
        CALL_METHOD(&calling, ci, cc);
    }
}

/* yield(args) */
insn
invokeblock(ci)(...)(val)
    CALL_INFO ci;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_depends_block; };
    attr rb_num_t sp_inc = { return 1 - ci->orig_argc; };

    impl {
        struct rb_calling_info calling;
        calling.argc = ci->orig_argc;
        calling.block_handler = VM_BLOCK_HANDLER_NONE;
        calling.recv = GET_SELF();

        val = vm_invoke_block(th, GET_CFP(), &calling, ci);
        if (val == Qundef) {
            RESTORE_REGS();
            NEXT_INSN();
        }
    }
}

/* return from this scope. */
insn
leave()(..., val)(val)
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = {
        /* This instruction pops stack frame. */
        return 1;
    };

    impl {
        if (OPT_CHECKED_RUN) {
            const VALUE *const bp = vm_base_ptr(reg_cfp);
            if (reg_cfp->sp - 1 != bp) {
                rb_bug("Stack consistency error (sp: %"PRIdPTRDIFF", bp: %"PRIdPTRDIFF")",
                       VM_SP_CNT(th, reg_cfp->sp) - 1, VM_SP_CNT(th, bp));
            }
        }

        RUBY_VM_CHECK_INTS(th);

        if (vm_pop_frame(th, GET_CFP(), GET_EP())) {
#if OPT_CALL_THREADED_CODE
            th->retval = val;
            return 0;
#else
            return val;
#endif
        }
        else {
            RESTORE_REGS();
        }
    }
}

/**********************************************************/
/* deal with control flow 3: exception                    */
/**********************************************************/

/* longjump */
insn
throw(throw_state)(throwobj)(val)
    rb_num_t throw_state;
    VALUE throwobj, val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        RUBY_VM_CHECK_INTS(th);
        val = vm_throw(th, GET_CFP(), throw_state, throwobj);
        THROW_EXCEPTION(val);
        /* unreachable */
    }
}

/**********************************************************/
/* deal with control flow 4: local jump                   */
/**********************************************************/

/* set PC to (PC + dst). */
insn
jump(dst)()()
    OFFSET dst;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        RUBY_VM_CHECK_INTS(th);
        JUMP(dst);
    }
}

/* if val is not false or nil, set PC to (PC + dst). */
insn
branchif(dst)(val)()
    OFFSET dst;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        if (RTEST(val)) {
            RUBY_VM_CHECK_INTS(th);
            JUMP(dst);
        }
    }
}

/* if val is false or nil, set PC to (PC + dst). */
insn
branchunless(dst)(val)()
    OFFSET dst;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        if (!RTEST(val)) {
            RUBY_VM_CHECK_INTS(th);
            JUMP(dst);
        }
    }
}

/* if val is nil, set PC to (PC + dst). */
insn
branchnil(dst)(val)()
    OFFSET dst;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        if (NIL_P(val)) {
            RUBY_VM_CHECK_INTS(th);
            JUMP(dst);
        }
    }
}

/**********************************************************/
/* for optimize                                           */
/**********************************************************/

/* push inline-cached value and go to dst if it is valid */
insn
getinlinecache(dst, ic)()(val)
    OFFSET dst;
    IC ic;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl {
        val = vm_ic_hit_p(ic, GET_EP());

        if (val != Qnil) {
            JUMP(dst);
        }
    }
}

/* set inline cache */
insn
setinlinecache(ic)(val)(val)
    IC ic;
    VALUE val;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { vm_ic_update(ic, val, GET_EP()); }
}

/* run iseq only once */
insn
once(iseq, ic)()(val)
    ISEQ iseq;
    IC ic;
    VALUE val;
{
    attr enum insn_purity purity = {
        /* once can lock threads; thus have global side effects. */
        return insn_is_not_pure;
    };

    impl {
        union iseq_inline_storage_entry *is = (union iseq_inline_storage_entry *)ic;

#define RUNNING_THREAD_ONCE_DONE ((rb_thread_t *)(0x1))
      retry:
        if (is->once.running_thread == RUNNING_THREAD_ONCE_DONE) {
            val = is->once.value;
        }
        else if (is->once.running_thread == NULL) {
            is->once.running_thread = th;
            val = is->once.value = rb_ensure(vm_once_exec, (VALUE)iseq, vm_once_clear, (VALUE)is);
            /* is->once.running_thread is cleared by vm_once_clear() */
            is->once.running_thread = RUNNING_THREAD_ONCE_DONE; /* success */
            rb_iseq_add_mark_object(GET_ISEQ(), val);
        }
        else if (is->once.running_thread == th) {
            /* recursive once */
            val = vm_once_exec((VALUE)iseq);
        }
        else {
            /* waiting for finish */
            RUBY_VM_CHECK_INTS(th);
            rb_thread_schedule();
            goto retry;
        }
    }
}

/* case dispatcher, jump by table if possible */
insn
opt_case_dispatch(hash, else_offset)(..., key)()
    CDHASH hash;
    OFFSET else_offset;
    VALUE key;
{
    attr enum insn_purity purity = { return insn_is_pure; };
    attr rb_num_t sp_inc = { return -1; };

    impl {
        OFFSET dst = vm_case_dispatch(hash, else_offset, key);

        if (dst) {
            JUMP(dst);
        }
    }
}

/** simple functions */

/* optimized X+Y. */
insn
opt_plus(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_PLUS, cc); };

    impl {
        val = vm_opt_plus(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X-Y. */
insn
opt_minus(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_MINUS, cc); };

    impl {
        val = vm_opt_minus(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X*Y. */
insn
opt_mult(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_MULT, cc); };

    impl {
        val = vm_opt_mult(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X/Y. */
insn
opt_div(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_DIV, cc); };

    impl {
        val = vm_opt_div(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X%Y. */
insn
opt_mod(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_MOD, cc); };

    impl {
        val = vm_opt_mod(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X==Y. */
insn
opt_eq(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = {
        /* this is complicated */
        if (cc_is_stale(cc)) {
            /* cc not used, BOP in effect */
            if (purity_of_BOP(BOP_EQ, ~0) == insn_is_pure) {
                return insn_is_pure; /* yes it is */
            }
            else {
                /* this caller site has never been reached yet */
                return insn_is_unpredictable;
            }
        }
        else {
            /* cc filled, should honor that */
            if (purity_cc_cfunc_is(cc, rb_obj_equal)) {
                return insn_is_pure; /* yes it is */
            }
            else {
                return purity_of_cc(cc);
            }
        }
    };

    impl {
        val = opt_eq_func(recv, obj, ci, cc);

        if (val == Qundef) {
            /* other */
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X!=Y. */
insn
opt_neq(ci, cc, ci_eq, cc_eq)(recv, obj)(val)
    CALL_INFO ci, ci_eq;
    CALL_CACHE cc, cc_eq;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = {
        /* this is even more complicated than opt_eq. */
        extern VALUE rb_obj_not_equal(VALUE obj1, VALUE obj2);

        if (cc_is_stale(cc)) {
            return insn_is_unpredictable;
        }
        else if (purity_cc_cfunc_is(cc, rb_obj_not_equal)) {
            return CALL_ATTRIBUTE(purity, opt_eq, ci_eq, cc_eq);
        }
        else {
            return purity_of_cc(cc);
        }
    };

    impl {
        val = vm_opt_neq(ci, cc, ci_eq, cc_eq, recv, obj);

        if (val == Qundef) {
            /* other */
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X<Y. */
insn
opt_lt(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_LT, cc); };

    impl {
        val = vm_opt_lt(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X<=Y. */
insn
opt_le(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_LE, cc); };

    impl {
        val = vm_opt_le(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X>Y. */
insn
opt_gt(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_GT, cc); };

    impl {
        val = vm_opt_gt(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized X>=Y. */
insn
opt_ge(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_GE, cc); };

    impl {
        val = vm_opt_ge(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* << */
insn
opt_ltlt(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_LTLT, cc); };

    impl {
        val = vm_opt_ltlt(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* [] */
insn
opt_aref(ci, cc)(recv, obj)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_AREF, cc); };

    impl {
        val = vm_opt_aref(recv, obj);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* recv[obj] = set */
insn
opt_aset(ci, cc)(recv, obj, set)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, obj, set, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_ASET, cc); };

    impl {
        val = vm_opt_aset(recv, obj, set);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* recv[str] = set */
insn
opt_aset_with(ci, cc, key)(recv, val)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE key, recv, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_ASET, cc); };

    impl {
        val = vm_opt_aset_with(recv, key, val);

        if (val == Qundef) {
            INC_SP(1);
            TOPN(0) = TOPN(1);
            TOPN(1) = rb_str_resurrect(key);
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* recv[str] */
insn
opt_aref_with(ci, cc, key)(recv)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE key, recv, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_AREF, cc); };

    impl {
        val = vm_opt_aref_with(recv, key);

        if (val == Qundef) {
            PUSH(rb_str_resurrect(key));
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized length */
insn
opt_length(ci, cc)(recv)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_LENGTH, cc); };

    impl {
        val = vm_opt_length(recv, BOP_LENGTH);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized size */
insn
opt_size(ci, cc)(recv)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_SIZE, cc); };

    impl {
        val = vm_opt_length(recv, BOP_SIZE);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized empty? */
insn
opt_empty_p(ci, cc)(recv)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_EMPTY_P, cc); };

    impl {
        VALUE length = vm_opt_length(recv, BOP_EMPTY_P);

        if (length == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
        else if (length == INT2FIX(0)) {
            val = Qtrue;
        }
        else {
            val = Qfalse;
        }
    }
}

/* optimized succ */
insn
opt_succ(ci, cc)(recv)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, val;
{
    attr enum insn_purity purity = { return purity_of_optinsn(BOP_SUCC, cc); };

    impl {
        val = vm_opt_succ(recv);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized not */
insn
opt_not(ci, cc)(recv)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE recv, val;
{
    attr enum insn_purity purity = {
        if (cc_is_stale(cc)) {
            return insn_is_unpredictable;
        }
        else if (purity_cc_cfunc_is(cc, rb_obj_not)) {
            return insn_is_pure;
        }
        else {
            return purity_of_cc(cc);
        }
    };

    impl {
        val = vm_opt_not(ci, cc, recv);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(recv);
        }
    }
}

/* optimized regexp match */
insn
opt_regexpmatch1(r)(obj)(val)
    VALUE r, obj, val;
{
    attr enum insn_purity purity = {
        return purity_of_BOP(BOP_MATCH, REGEXP_REDEFINED_OP_FLAG);
    };

    impl { val = vm_opt_regexpmatch1(r, obj); }
}

/* optimized regexp match 2 */
insn
opt_regexpmatch2(ci, cc)(obj2, obj1)(val)
    CALL_INFO ci;
    CALL_CACHE cc;
    VALUE obj2, obj1, val;
{
    attr enum insn_purity purity = {
        return purity_of_optinsn(BOP_MATCH, cc);
    };

    impl {
        val = vm_opt_regexpmatch2(obj2, obj1);

        if (val == Qundef) {
            CALL_SIMPLE_METHOD(obj2);
        }
    }
}

/* call native compiled method */
insn
opt_call_c_function(funcptr)()()
    rb_insn_func_t funcptr;
{
    attr enum insn_purity purity = {
        return insn_is_not_pure; /* don't know what happens inside. */
    };

    impl {
        reg_cfp = (funcptr)(th, reg_cfp);

        if (reg_cfp == 0) {
            VALUE err = th->errinfo;
            th->errinfo = Qnil;
            THROW_EXCEPTION(err);
        }

        RESTORE_REGS();
        NEXT_INSN();
    }
}

/* BLT */
insn
bitblt()()(ret)
    VALUE ret;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { ret = rb_str_new2("a bit of bacon, lettuce and tomato"); }
}

/* The Answer to Life, the Universe, and Everything */
insn
answer()()(ret)
    VALUE ret;
{
    attr enum insn_purity purity = { return insn_is_pure; };

    impl { ret = INT2FIX(42); }
}
